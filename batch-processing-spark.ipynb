{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "static_count_word.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVJtH-XBoVIH"
      },
      "source": [
        "# Example 1: learning about Spark with a simple word counter.\n",
        "# Dataset: datasets/TextFileCountWords.txt\n",
        "# Author: Humberto Bianchini"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n3i0jWJoVIN"
      },
      "source": [
        "# 1) Importing all necessary libraries and Spark session creation.\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import explode\n",
        "from pyspark.sql.functions import split\n",
        "spark = SparkSession.builder.appName('WordCounter').getOrCreate()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5QWE-81oVIP"
      },
      "source": [
        "# 2) Reading the text file.\n",
        "read_file = spark\\\n",
        ".read\\\n",
        ".format(\"txt\")\\\n",
        ".option(\"inferSchema\", \"true\")\\\n",
        ".text(\"TextFileCountWords.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYIn0R3BoVIQ",
        "outputId": "4db1fb6e-b4ff-4d02-f5e9-4aca23a6a4c2"
      },
      "source": [
        "# 3) Printinf file schema.\n",
        "read_file.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- value: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfAwTJKsoVIR",
        "outputId": "ac929b40-7319-4726-f191-f24f0eb4ce99"
      },
      "source": [
        "# 4) Checking if the file contains one or more sources that continuously return data\n",
        "read_file.isStreaming"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL-7vKDAoVIU"
      },
      "source": [
        "# 5) Formating the rows of the file and creating a new dataframe\n",
        "words = read_file.select(explode(split(read_file.value, \" \")).alias(\"word\"))\n",
        "wordCounts = words.groupBy(\"word\").count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LAHuhmPoVIV",
        "outputId": "f600c8ef-a281-4922-f537-11e2be02766d"
      },
      "source": [
        "# 6) Showing the result.\n",
        "wordCounts.show(50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|      word|count|\n",
            "+----------+-----+\n",
            "|  condemns|    1|\n",
            "|       for|    1|\n",
            "|   tongues|    1|\n",
            "|    tongue|    1|\n",
            "|        in|    1|\n",
            "|      tale|    2|\n",
            "|conscience|    1|\n",
            "|        me|    1|\n",
            "|      hath|    1|\n",
            "|    brings|    1|\n",
            "|   villain|    1|\n",
            "|     every|    2|\n",
            "|        My|    1|\n",
            "|   several|    2|\n",
            "|         a|    3|\n",
            "|  thousand|    1|\n",
            "|       And|    2|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
        {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeFwpyS04Or8"
      },
      "source": [
        "# Nova seção"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h41VA9xKoVIX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
